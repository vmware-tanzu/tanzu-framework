#! Please add any overlays specific to AWS provider under this file.
#@ load("@ytt:overlay", "overlay")
#@ load("@ytt:data", "data")
#@ load("lib/helpers.star", "get_bom_data_for_tkr_name", "kubeadm_image_repo", "get_az_from_region")

#@ default_az_0 = get_az_from_region(data.values.AWS_REGION, data.values.AWS_NODE_AZ, "a")
#@ default_az_1 = get_az_from_region(data.values.AWS_REGION, data.values.AWS_NODE_AZ_1, "b")
#@ default_az_2 = get_az_from_region(data.values.AWS_REGION, data.values.AWS_NODE_AZ_2, "c")

#@ bomData = get_bom_data_for_tkr_name()

#@overlay/match by=overlay.subset({"kind":"AWSCluster"})
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: AWSCluster
metadata:
  name: #@ data.values.CLUSTER_NAME
spec:
  region: #@ data.values.AWS_REGION
  sshKeyName: #@ data.values.AWS_SSH_KEY_NAME
  bastion:
    enabled: #@ data.values.BASTION_HOST_ENABLED
  networkSpec:
    vpc:
      cidrBlock: #@ data.values.AWS_VPC_CIDR
      id: #@ data.values.AWS_VPC_ID
    subnets:
    #@ if data.values.AWS_VPC_ID == "" or data.values.AWS_PUBLIC_SUBNET_ID != "":
    #@overlay/append
    - availabilityZone: #@ default_az_0
      cidrBlock: #@ data.values.AWS_PUBLIC_NODE_CIDR
      isPublic: true
      id: #@ data.values.AWS_PUBLIC_SUBNET_ID
    #@ end
    #@overlay/match by=overlay.index(0)
    #@overlay/replace
    - availabilityZone: #@ default_az_0
      cidrBlock: #@ data.values.AWS_PRIVATE_NODE_CIDR
      id: #@ data.values.AWS_PRIVATE_SUBNET_ID

#@ if data.values.CLUSTER_PLAN == "prod":
#@overlay/match by=overlay.subset({"kind":"AWSCluster"})
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: AWSCluster
spec:
  networkSpec:
    subnets:
    #@ if data.values.AWS_VPC_ID == "" or data.values.AWS_PUBLIC_SUBNET_ID_1 != "":
    #@overlay/append
    - availabilityZone: #@ default_az_1
      cidrBlock: #@ data.values.AWS_PUBLIC_NODE_CIDR_1
      isPublic: true
      id: #@ data.values.AWS_PUBLIC_SUBNET_ID_1
    #@ end
    #@overlay/append
    - availabilityZone: #@ default_az_1
      cidrBlock: #@ data.values.AWS_PRIVATE_NODE_CIDR_1
      id: #@ data.values.AWS_PRIVATE_SUBNET_ID_1
    #@ if data.values.AWS_VPC_ID == "" or data.values.AWS_PUBLIC_SUBNET_ID_2 != "":
    #@overlay/append
    - availabilityZone: #@ default_az_2
      cidrBlock: #@ data.values.AWS_PUBLIC_NODE_CIDR_2
      isPublic: true
      id: #@ data.values.AWS_PUBLIC_SUBNET_ID_2
    #@ end
    #@overlay/append
    - availabilityZone: #@ default_az_2
      cidrBlock: #@ data.values.AWS_PRIVATE_NODE_CIDR_2
      id: #@ data.values.AWS_PRIVATE_SUBNET_ID_2
---
apiVersion: cluster.x-k8s.io/v1alpha3
kind: MachineDeployment
metadata:
  name: #@ "{}-md-1".format(data.values.CLUSTER_NAME)
spec:
  clusterName: #@ data.values.CLUSTER_NAME
  replicas: #@ data.values.WORKER_MACHINE_COUNT_1
  selector:
    matchLabels: null
  template:
    metadata:
      labels:
        node-pool: #@ "{}-worker-pool".format(data.values.CLUSTER_NAME)
    spec:
      clusterName: #@ data.values.CLUSTER_NAME
      version: #@ data.values.KUBERNETES_VERSION
      bootstrap:
        configRef:
          name: #@ "{}-md-1".format(data.values.CLUSTER_NAME)
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
          kind: KubeadmConfigTemplate
      infrastructureRef:
        name: #@ "{}-md-1".format(data.values.CLUSTER_NAME)
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
        kind: AWSMachineTemplate
      failureDomain: #@ default_az_1
---
apiVersion: cluster.x-k8s.io/v1alpha3
kind: MachineDeployment
metadata:
  name: #@ "{}-md-2".format(data.values.CLUSTER_NAME)
spec:
  clusterName: #@ data.values.CLUSTER_NAME
  replicas: #@ data.values.WORKER_MACHINE_COUNT_2
  selector:
    matchLabels: null
  template:
    metadata:
      labels:
        node-pool: #@ "{}-worker-pool".format(data.values.CLUSTER_NAME)
    spec:
      clusterName: #@ data.values.CLUSTER_NAME
      version: #@ data.values.KUBERNETES_VERSION
      bootstrap:
        configRef:
          name: #@ "{}-md-2".format(data.values.CLUSTER_NAME)
          apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
          kind: KubeadmConfigTemplate
      infrastructureRef:
        name: #@ "{}-md-2".format(data.values.CLUSTER_NAME)
        apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
        kind: AWSMachineTemplate
      failureDomain: #@ default_az_2
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: AWSMachineTemplate
metadata:
  name: #@ "{}-md-1".format(data.values.CLUSTER_NAME)
spec:
  template:
    spec:
      instanceType: #@ data.values.NODE_MACHINE_TYPE
      iamInstanceProfile: "nodes.tkg.cloud.vmware.com"
      sshKeyName: #@ data.values.AWS_SSH_KEY_NAME
      ami:
        id: #@ data.values.AWS_AMI_ID
      rootVolume:
        size: #@ int(data.values.AWS_NODE_OS_DISK_SIZE_GIB) or 80
---
apiVersion: infrastructure.cluster.x-k8s.io/v1alpha3
kind: AWSMachineTemplate
metadata:
  name: #@ "{}-md-2".format(data.values.CLUSTER_NAME)
spec:
  template:
    spec:
      instanceType: #@ data.values.NODE_MACHINE_TYPE
      iamInstanceProfile: "nodes.tkg.cloud.vmware.com"
      sshKeyName: #@ data.values.AWS_SSH_KEY_NAME
      ami:
        id: #@ data.values.AWS_AMI_ID
      rootVolume:
        size: #@ int(data.values.AWS_NODE_OS_DISK_SIZE_GIB) or 80
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
kind: KubeadmConfigTemplate
metadata:
  name: #@ "{}-md-1".format(data.values.CLUSTER_NAME)
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          name: '{{ ds.meta_data.local_hostname }}'
          kubeletExtraArgs:
            cloud-provider: aws
---
apiVersion: bootstrap.cluster.x-k8s.io/v1alpha3
kind: KubeadmConfigTemplate
metadata:
  name: #@ "{}-md-2".format(data.values.CLUSTER_NAME)
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          name: '{{ ds.meta_data.local_hostname }}'
          kubeletExtraArgs:
            cloud-provider: aws
#@ end
